import subprocess
import time
from tqdm import tqdm
import sys
import os

# üß≠ Se positionner dans le dossier racine du projet (l√† o√π sont les scripts)
os.chdir(os.path.dirname(os.path.dirname(__file__)))

PIPELINES = [
    {"name": " 1Ô∏è‚É£ ETL Indices majeurs (S&P500, CAC40, Nikkei)", "script": "etl_pipeline.py", "steps": 14},
    {"name": " 2Ô∏è‚É£ Enrichissement Small Caps (filtres suppl√©mentaires)", "script": "enrich_etl.py", "steps": 2},
    {"name": " 3Ô∏è‚É£ Fusion finale des donn√©es", "script": "merge_uniform.py", "steps": 2},

    {"name": " 4Ô∏è‚É£ Donn√©es Overview G√©n√©rales", "script": "generate_overview_full.py", "steps": 5},
    {"name": " 5Ô∏è‚É£ Index Data", "script": "Index_data.py", "steps": 2},
    {"name": " 6Ô∏è‚É£ Enrichissement Compagnies", "script": "enrich_companies.py", "steps": 3},

    {"name": " 7Ô∏è‚É£ Raffinement Compagnies", "script": "refine_companies.py", "steps": 2},
    {"name": " 8Ô∏è‚É£ Analyse News (GPT)", "script": "enrich_sent_gpt.py", "steps": 3},
    {"name": " 9Ô∏è‚É£ Fusion News", "script": "merge_news_gpt.py", "steps": 2},
    {"name": " üîü Nettoyage fichiers JSON", "script": "clean_json_files.py", "steps": 1},

    {"name": " üîÅ G√©n√©ration df_sentiment_full", "script": "generate_df_sentiment_full.py", "steps": 2},
    {"name": " üì¶ Archivage du snapshot quotidien", "script": "archive_daily_snapshot.py", "steps": 1}
]

def run_pipeline_with_progress(pipeline):
    name = pipeline["name"]
    script = pipeline["script"]
    steps = pipeline["steps"]
    step_percent = 100 // steps

    print(f"\nüîß D√©marrage de : {name}")
    progress_bar = tqdm(total=100, desc=name, bar_format="{l_bar}{bar}| {n_fmt}%", ncols=100)

    process = subprocess.Popen(
        ["python", f"{script}"],
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        bufsize=1,
        universal_newlines=True
    )

    progress = 0
    for line in process.stdout:
        sys.stdout.write(line)
        sys.stdout.flush()
        if any(kw in line.lower() for kw in [
            "√©tape", "step", "extraction", "nettoyage", "short", "midterm", "shortterm",
            "r√©sum√©", "visualisation", "enrich", "fiche", "json", "lecture", "sauvegarde", "df"
        ]):
            progress = min(progress + step_percent, 100)
            progress_bar.n = progress
            progress_bar.refresh()

    process.stdout.close()
    returncode = process.wait()
    progress_bar.n = 100
    progress_bar.refresh()
    progress_bar.close()

    if returncode == 0:
        print(f"‚úÖ {name} termin√© avec succ√®s.")
        return True
    else:
        print(f"‚ùå Erreur pendant l'ex√©cution de {name}. Code de retour : {returncode}")
        return False

def run_all_pipelines():
    print("\nüöÄ Lancement des pipelines de traitement complet...\n")

    # Batch 1 - ETL Companies (s√©quentiel)
    for i in range(3):
        if not run_pipeline_with_progress(PIPELINES[i]):
            print("‚õî Arr√™t du pipeline suite √† une erreur (Batch 1).")
            return

    # Batch 2 - Overview (parall√©lisable)
    overview_proc = []
    for i in range(3, 5):
        name = PIPELINES[i]["name"]
        script = f"{PIPELINES[i]['script']}"
        print(f"‚ñ∂Ô∏è Lancement parall√®le : {name}")
        overview_proc.append(subprocess.Popen(["python", script]))

    # Batch 3 - enrich + refine
    if not run_pipeline_with_progress(PIPELINES[5]):  # enrich_companies
        print("‚õî Arr√™t du pipeline suite √† une erreur (Batch 3.1).")
        return

    if not run_pipeline_with_progress(PIPELINES[6]):  # refine_companies
        print("‚õî Arr√™t du pipeline suite √† une erreur (Batch 3.2).")
        return

    # Batch 4 - Analyse GPT & fusion
    if not run_pipeline_with_progress(PIPELINES[7]):  # enrich_sent_gpt
        print("‚õî Arr√™t du pipeline suite √† une erreur (Batch 4.1).")
        return

    if not run_pipeline_with_progress(PIPELINES[8]):  # merge_news_gpt
        print("‚õî Arr√™t du pipeline suite √† une erreur (Batch 4.2).")
        return

    if not run_pipeline_with_progress(PIPELINES[9]):  # clean_json_files
        print("‚õî Arr√™t du pipeline suite √† une erreur (Batch 4.3).")
        return

    # Batch 5 - Sentiment full + archivage
    if not run_pipeline_with_progress(PIPELINES[10]):  # generate_df_sentiment_full
        print("‚õî Arr√™t du pipeline suite √† une erreur (Batch 5.1).")
        return

    if not run_pipeline_with_progress(PIPELINES[11]):  # archive_daily_snapshot
        print("‚õî Arr√™t du pipeline suite √† une erreur (Batch 5.2).")
        return

    # Fin des scripts parall√®les
    for p in overview_proc:
        p.wait()

    print("\nüéØ Tous les pipelines ont √©t√© ex√©cut√©s avec succ√®s.")

if __name__ == "__main__":
    run_all_pipelines()
